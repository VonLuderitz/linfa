searchState.loadedDescShard("linfa_preprocessing", 0, "Preprocessing\nCounts the occurrences of each vocabulary entry, learned …\nCount vectorizer: learns a vocabulary from a sequence of …\nIf true, all documents used for fitting will be converted …\nSpecifies the minimum and maximum (relative) document …\nError definitions for preprocessing\nLearns a vocabulary from the documents in <code>x</code>, according to …\nLearns a vocabulary from the documents in <code>x</code>, according to …\nLearns a vocabulary from the documents contained in the …\nLearns a vocabulary from the documents contained in the …\nProduces a CountVectorizer with the input vocabulary. All …\nProduces a CountVectorizer with the input vocabulary. All …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nLinear Scaling methods\nIf set to <code>(1,1)</code> single tokens will be candidate vocabulary …\nNumber of vocabulary entries learned during fitting\nSample normalization methods\nIf true, all charachters in the documents used for fitting …\nConstruct a new set of parameters\nSets the regex espression used to split decuments into …\nList of entries to be excluded from the generated …\nTerm frequency - inverse document frequency vectorization …\nGiven a sequence of <code>n</code> documents, produces a sparse array …\nGiven a sequence of <code>n</code> file names, produces a sparse array …\nContains all vocabulary entries, in the same order used by …\nMethods for uncorrelating data\nContains the error value\nContains the success value\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThe result of fitting a linear scaler. Scales datasets …\nLinear Scaler: learns scaling parameters, according to the …\nPossible scaling methods for LinearScaler\nFits the input dataset accordng to the scaler method. Will …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nInitializes a MaxAbs scaler\nSetter for the scaler method\nReturns the method used for fitting. Useful for printing, …\nInitializes a MinMax scaler with range <code>0..=1</code>\nInitializes a MinMax scaler with the specified minimum and …\nInitializes the scaler with the specified method.\nArray of size <code>n_features</code> that contains the offset that …\nArray of size <code>n_features</code> that contains the scale that will …\nInitializes a Standard scaler\nInitializes a Standard scaler that does not subract the …\nInitializes a Stadard scaler that does not scale the …\nScales an array of size (nsamples, nfeatures) according to …\nSubstitutes the records of the dataset with their scaled …\nNorm scaler: scales all samples in a dataset to have unit …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nInitializes a norm scaler that uses l1 norm\nInitializes a norm scaler that uses l2 norm\nInitializes a norm scaler that uses max norm\nScales all samples in the array of shape (nsamples, …\nSubstitutes the records of the dataset with their scaled …\nCounts the occurrences of each vocabulary entry, learned …\nComputes the idf as <code>log(n/document_frequency) +1</code>. The “…\nComputes the idf as <code>log(1+n/1+document_frequency) + 1</code>. The …\nTextbook definition of idf, computed as …\nMethods for computing the inverse document frequency of a …\nSimlar to <code>CountVectorizer</code> but instead of just counting the …\nIf true, all documents used for fitting will be converted …\nSpecifies the minimum and maximum (relative) document …\nLearns a vocabulary from the texts in <code>x</code>, according to the …\nProduces a FittedTfIdfVectorizer with the input vocabulary.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns the inverse document frequency method used in the …\nIf set to <code>(1,1)</code> single tokens will be candidate vocabulary …\nNumber of vocabulary entries learned during fitting\nIf true, all charachters in the documents used for fitting …\nSets the regex espression used to split decuments into …\nList of entries to be excluded from the generated …\nGiven a sequence of <code>n</code> documents, produces an array of size …\nConstains all vocabulary entries, in the same order used …\nStruct that can be used to whiten data. Data will be …\nStruct that can be fitted to the input data to obtain the …\nCreates an instance of a Whitener that uses the cholesky …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe means that will be subtracted to the features before …\nCreates an instance of a Whitener that uses the PCA method\nThe matrix used for scaling the data\nCreates an instance of a Whitener that uses the ZCA …")